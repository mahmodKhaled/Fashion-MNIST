{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreparator():\n",
    "    def __init__(self, X, y):\n",
    "        self.X_train, self.X_test = X\n",
    "        self.y_train, self.y_test = y\n",
    "\n",
    "    def draw_images(self, num_of_images):\n",
    "        '''\n",
    "        This function draws a random images from the data, by specifying how many images to draw\n",
    "        '''\n",
    "        random_indexes = [np.random.randint(0, len(self.X_train)) for i in range(num_of_images)]\n",
    "        fig , axis = plt.subplots(5,10)\n",
    "        fig.set_figwidth(15)\n",
    "        fig.set_figheight(15)\n",
    "        i , j = 0 , 0\n",
    "        for idx in random_indexes:\n",
    "            image = self.X_train[idx]\n",
    "            axis[i,j].imshow(image, cmap='binary')\n",
    "            axis[i,j].axis('off')\n",
    "            j += 1\n",
    "            if j % 10 == 0:\n",
    "                i += 1\n",
    "                j = 0\n",
    "    \n",
    "    def normalize_data(self, value):\n",
    "        '''\n",
    "        This function normalize the data by dividing it by the value\n",
    "        '''\n",
    "        self.X_train = self.X_train / value\n",
    "        self.X_test = self.X_test / value\n",
    "        return self.X_train, self.X_test\n",
    "    \n",
    "    def reshape_data(self, axis):\n",
    "        self.X_train = np.expand_dims(self.X_train, axis=axis)\n",
    "        self.X_test = np.expand_dims(self.X_test, axis=axis)\n",
    "        return self.X_train, self.X_test\n",
    "    \n",
    "    def encode_labels(self):\n",
    "        self.y_train = pd.get_dummies(self.y_train)\n",
    "        self.y_test = pd.get_dummies(self.y_test)\n",
    "        return self.y_train, self.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainLogs():\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    # Plot Utility\n",
    "    def train_curves(self, history, special_title):\n",
    "        '''\n",
    "        This function draws accuracy and loss curves for each epoch between train and validation data\n",
    "        '''\n",
    "        title_loss = 'Model loss per epoch ' + special_title\n",
    "        title_accuracy = 'Model accuracy per epoch ' + special_title\n",
    "        fig , axis = plt.subplots(nrows=1, ncols=2)\n",
    "        # dimensions of figure\n",
    "        fig.set_figheight(6)\n",
    "        fig.set_figwidth(14)\n",
    "        # loss\n",
    "        loss = history.history['loss']\n",
    "        val_loss = history.history['val_loss']\n",
    "        # accuracy\n",
    "        accuracy = history.history['accuracy']\n",
    "        val_accuracy = history.history['val_accuracy']\n",
    "        epoch = np.arange(150)\n",
    "        # loss curve\n",
    "        axis[0].plot(loss,label='Train')\n",
    "        axis[0].plot(val_loss,label='Validation')\n",
    "        axis[0].set_xlabel('epoch')\n",
    "        axis[0].set_ylabel('loss')\n",
    "        axis[0].set_title(title_loss)\n",
    "        axis[0].legend()\n",
    "        # accuracy curve\n",
    "        axis[1].plot(accuracy, label='Train')\n",
    "        axis[1].plot(val_accuracy, label='Validation')\n",
    "        axis[1].set_xlabel('epoch')\n",
    "        axis[1].set_ylabel('accuracy')\n",
    "        axis[1].set_title(title_accuracy)\n",
    "        axis[1].legend()\n",
    "    \n",
    "    # Evaluation Utilities\n",
    "    def k_fold_cross_validation(self, X, y, k, batch_size=256, compiled_model = None):\n",
    "        '''\n",
    "        This function evaluates the model by performing k fold cross validation\n",
    "        '''\n",
    "        # instantiate k_fold \n",
    "        k_fold = StratifiedKFold(k, shuffle=True, random_state=42)\n",
    "        # output lists that will hold accuracy and loss for both train and validation\n",
    "        # for each fold\n",
    "        history_list = []\n",
    "        accuracy_list = []\n",
    "        val_accuracy_list = []\n",
    "        val_loss_list = []\n",
    "        loss_list = []\n",
    "        # loop through the 5 folds\n",
    "        for train_idx , val_idx in k_fold.split(X,y):\n",
    "            # determine from the train data which fold will be used for validation, and the other will be for training\n",
    "            X_train , y_train = X[train_idx], y[train_idx]\n",
    "            X_val , y_val = X[val_idx], y[val_idx]\n",
    "            # encode the labels\n",
    "            y_train , y_val = pd.get_dummies(y_train) , pd.get_dummies(y_val)\n",
    "            if compiled_model is None:\n",
    "                model = self.model\n",
    "            else:\n",
    "                model = compiled_model\n",
    "            # training...\n",
    "            history = model.fit(x= X_train, y= y_train, epochs=25,  batch_size= batch_size, validation_data= (X_val, y_val), verbose= 0)\n",
    "            # accuracy and loss after the completion of training\n",
    "            accuracy = history.history['accuracy']\n",
    "            val_accuracy = history.history['val_accuracy']\n",
    "            loss = history.history['loss']\n",
    "            val_loss = history.history['val_loss']\n",
    "            history_list.append(history)\n",
    "            accuracy_list.append(accuracy)\n",
    "            loss_list.append(loss)\n",
    "            val_accuracy_list.append(val_accuracy)\n",
    "            val_loss_list.append(val_loss)\n",
    "        # get the mean of results for all folds\n",
    "        mean_accuracy = np.mean(accuracy_list)\n",
    "        mean_val_accuracy = np.mean(val_accuracy_list)\n",
    "        mean_loss = np.mean(loss_list)\n",
    "        mean_val_loss = np.mean(val_loss_list)\n",
    "        return history_list, mean_accuracy, mean_val_accuracy, mean_loss,  mean_val_loss\n",
    "    \n",
    "    def cross_validation_report(self, history_list, mean_accuracy, mean_val_accuracy, mean_loss,  mean_val_loss, k, title):\n",
    "        print('The mean accuracy of the model after', k, 'fold cross validation is:', mean_accuracy)\n",
    "        print('The mean validation accuracy of the model after', k, 'fold cross validation is:', mean_val_accuracy)\n",
    "        print('The mean loss of the model after', k, 'fold cross validation is:', mean_loss)\n",
    "        print('The mean validation loss of the model after', k, 'fold cross validation is:', mean_val_loss)\n",
    "        for i, history in enumerate(history_list,start=1):\n",
    "            self.train_curves(history, 'of fold-' + str(i) + title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
